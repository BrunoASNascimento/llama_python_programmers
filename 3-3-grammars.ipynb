{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "from_string grammar:\n",
      "root ::= root_6 \n",
      "root_1 ::= question root_4 epilog [<U+000A>] \n",
      "question ::= sentence [<U+000A>] | sentence [ ] sentence [<U+000A>] \n",
      "answer ::= [A-Z] [)] [ ] sentence [<U+000A>] \n",
      "root_4 ::= answer root_4 | answer \n",
      "epilog ::= [A] [N] [S] [W] [E] [R] [:] [ ] [A-Z] [<U+000A>] \n",
      "root_6 ::= root_1 root_6 | root_1 \n",
      "sentence ::= [A-Z] sentence_8 sentence_9 \n",
      "sentence_8 ::= [A-Za-z0-9 ,-] sentence_8 | \n",
      "sentence_9 ::= [.] | [!] | [?] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a fruiting body?\n",
      "A) A group of mushrooms that grow together in a single colony.\n",
      "B)"
     ]
    }
   ],
   "source": [
    "# Let's load and configure our llama 2 model\n",
    "import os\n",
    "from llama_cpp import Llama\n",
    "from llama_cpp.llama_types import *\n",
    "from llama_cpp.llama_grammar import *\n",
    "\n",
    "model: Llama = Llama(model_path=os.environ[\"LLAMA_13B\"], verbose=False, n_ctx=2048)\n",
    "\n",
    "# Our prompt will just be a list of Mushroom questions in Aiken format\n",
    "prompt='''Most common edible wild mushrooms are which of the following colors?\n",
    "A) White, cream or ivory\n",
    "B) Red\n",
    "C) Orange or yellow\n",
    "D) Green\n",
    "ANSWER: A\n",
    "\n",
    "What is a sporangium?\n",
    "A) The term for mushroom gills that contain spores\n",
    "B) The fruiting body of the mushroom\n",
    "C) The sac-like structure on which spore are produced\n",
    "D) A slender, thread like hyphae\n",
    "ANSWER: C\n",
    "\n",
    "What is a mycelium?\n",
    "A) Sporangia covered with colorful scales or ridges\n",
    "B) Undifferentiated mass of branching filaments\n",
    "C) The stem of the mushroom that carries spores from the fruiting body to the soil where it will grow and reproduce.\n",
    "D) The cap of a mushroom\n",
    "ANSWER: D\n",
    "\n",
    "'''\n",
    "\n",
    "grammar= r'''\n",
    "root ::= (question answer+ epilog \"\\n\")+\n",
    "# A sentence is just alphanumerica latin values, plus punctuation and whitespace\n",
    "# No parentheticals are allowed in a sentence, but a comma and hyphen are\n",
    "sentence ::= [A-Z] [A-Za-z0-9 ,-]* (\".\" | \"!\" | \"?\")\n",
    "# A question should be a sentence or two, no more.\n",
    "question ::= sentence \"\\n\" | sentence \" \" sentence \"\\n\"\n",
    "# An answer is a capital letter followed by a close parens and then a sentence\n",
    "answer ::= [A-Z] \") \" sentence \"\\n\"\n",
    "# The question closes with an epilog telling us the question has finished\n",
    "epilog ::= \"ANSWER: \" [A-Z] \"\\n\"\n",
    "'''\n",
    "\n",
    "# Finally, let's invoke a completion\n",
    "result = model.create_completion(prompt,\n",
    "    grammar=LlamaGrammar.from_string(grammar=grammar), \n",
    "    stream=True, \n",
    "    max_tokens=2048)\n",
    "for item in result:\n",
    "    print(item['choices'][0]['text'], end=\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
