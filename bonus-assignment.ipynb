{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Assignment\n",
    "\n",
    "**This assignment is just for fun -- something to challenge yourself, and does not affect your grade, certificate, or ability to pass the course!**\n",
    "\n",
    "In this assignment you must write a python application which presents a game with llama 2. The goal is to combine what you have learned about the use of the chat model, few shot prompting, and llama.cpp grammars, into a full application where the llama 2 model must traverse a \"dungeon\", searching for treasure while it tries to find its way home. A basic scaffold is provided below, but you must fill in the grammar and prompt to ensure that the application generates a log of moves which are allowable.\n",
    "\n",
    "The game rules are as follows:\n",
    "\n",
    "0. You must write your assignment code in this notebook, and you must only change the code in the `solution` function in the next cell. Do not add, edit, or delete other cells.\n",
    "1. You must use the model object I provide, it will be the 13B llama 2 chat model\n",
    "2. You must use the list of messages I provide, it will be empty when I call your function and you must fill it with a conversation log for me to verify the game is proceeding appropriately\n",
    "3. You will be given two locations, a `start_location` and a `home_location`. These are provided as X,Y tuples and will be integer values. The llama's goal is to try and move from the `start_location` to the `home_location`.\n",
    "4. At any turn you must constrain the llama so that it can do one of two things: Move or Search. If it moves, it must follow that command with a space and then a direction, one of North, East, South, West. For instance, the llama can respond with \"Move East\", \"Move North\", or \"Search\". It must not respond with any other characters or text.\n",
    "5. You will be given a maximum number of turns, as an integer, which the llama can play. This is the maximum number of times it is allowed to respond to you.\n",
    "6. You can give the llama hints in the user prompts, but at the very least you **must** tell it where it is in (X,Y) notation. For example, the response \"You are now at location (1,2)\", if the llama moved North once and East twice would be appropriate, or \"Going down! You have gotten to location (-2,0) -- where to next?\" would be an appropriate response for a llama that has moved South twice, assuming that the `start_location=(0,0)`.\n",
    "\n",
    "I have included an example test function in the last cell of this notebook. It will help you determine if your solution is of the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from llama_cpp import Llama\n",
    "from llama_cpp.llama_types import *\n",
    "from llama_cpp.llama_grammar import *\n",
    "\n",
    "def solution(model:Llama, \n",
    "             messages: list[ChatCompletionMessage], \n",
    "             start_location: tuple[int, int], \n",
    "             home_location: tuple[int, int],\n",
    "             max_turns: int) -> None:\n",
    "    # Your code goes here\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # The following code is an example of what a grader might look like, but there are no\n",
    "    # grades for this assignment - it's just for fun!\n",
    "    \n",
    "    # Load the chat model with a full sized context window\n",
    "    model: Llama = Llama(model_path=os.environ[\"LLAMA_13B_CHAT\"], verbose=False, n_ctx=4096)\n",
    "    \n",
    "    # Set the starting location of the llama and the ending location\n",
    "    # in cartesian coordinates (x,y) space\n",
    "    start_location: tuple[int, int] = (0,0)\n",
    "    home_location: tuple[int, int] = (1,1)\n",
    "\n",
    "    # Set the maximum number of turns the llama is allows to ha ve\n",
    "    max_turns: int = 20\n",
    " \n",
    "    # The system prompt is the first message and up to the student to write,\n",
    "    # I'll just create an empty list and they will fill that list with ChatCompetionMessage\n",
    "    # objects, then the autograder can inspect those\n",
    "    messages: list[ChatCompletionMessage] = []\n",
    "\n",
    "    # Invoke the student solution, populating the messages list\n",
    "    worked_solution(model, messages, start_location, home_location, max_turns)\n",
    "\n",
    "    # Now ensure that the llama has been appropriately constrained\n",
    "    turns_taken: int = 0\n",
    "    for message in messages:\n",
    "        print(message)\n",
    "        # Process it if it's a llama 2 message\n",
    "        if message[\"role\"]==\"agent\":\n",
    "            # Verify that the message is one of the allowed ones\n",
    "            assert message[\"content\"] in [\"Move East\", \"Move West\", \"Move South\", \"Move North\", \"Search\"], \"One of the responses back from llama 2 was not a correct option, maybe your grammar is incorrect?\"\n",
    "            turns_taken = turns_taken+1\n",
    "        \n",
    "        # Check if it's a human message, since that message should tell the llama where they are\n",
    "        # Anything else the user wants to tell them is fine\n",
    "        if message[\"role\"]==\"user\":\n",
    "            assert len(re.findall(r'\\([-]?[\\d]*,[-]?[\\d]*\\)', message[\"content\"]))>0, \"You must tell the llama where it is each turn, and that should match the pattern (n,m) where n and m are integers.\"\n",
    "\n",
    "    # Verify that the llama did not take more than 20 turns\n",
    "    assert(turns_taken<=max_turns), \"You must restrict the number of turns the llama takes, we don't have all day here!\"\n",
    "\n",
    "    # Since we have gotten to the end of the block they did it!\n",
    "    print(\"Looks great!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
